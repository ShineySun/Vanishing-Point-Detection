{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm_ver2.ipynb  mnist_lstm.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tusimple Dataset Management Tool\n",
    "class Tusimple_Manager(object):\n",
    "    # initialize\n",
    "    def __init__(self, root_dir = '/home/sun/tusimple'):\n",
    "        # train data root path\n",
    "        self.train_path = root_dir + '/train_set/'\n",
    "        # test data root path\n",
    "        self.test_path = root_dir + '/test_set/'\n",
    "        # train data annotation files\n",
    "        self.train_label_files = ['label_data_0313.json' , 'label_data_0531.json' , 'label_data_0601.json']\n",
    "        # test data annotation files\n",
    "        self.test_label_files = ['test_label.json']\n",
    "\n",
    "        # train annotation data\n",
    "        self.train_data = []\n",
    "        # train data size\n",
    "        self.train_size = 0\n",
    "        # test annotation data\n",
    "        self.test_data = []\n",
    "        # test data size\n",
    "        self.test_size = 0\n",
    "\n",
    "        # number of train_instance 1\n",
    "        self.train_instance_1 = []\n",
    "        # number of train_instance 2\n",
    "        self.train_instance_2 = []\n",
    "        # number of train_instance 3\n",
    "        self.train_instance_3 = []\n",
    "        # number of train_instance 4\n",
    "        self.train_instance_4 = []\n",
    "        # number of train_instance 5\n",
    "        self.train_instance_5 = []\n",
    "        # number of train_instance 6\n",
    "        self.train_instance_6 = []\n",
    "\n",
    "\n",
    "        # number of test_instance 1\n",
    "        self.test_instance_1 = []\n",
    "        # number of test_instance 2\n",
    "        self.test_instance_2 = []\n",
    "        # number of test_instance 3\n",
    "        self.test_instance_3 = []\n",
    "        # number of test_instance 4\n",
    "        self.test_instance_4 = []\n",
    "        # number of test_instance 5\n",
    "        self.test_instance_5 = []\n",
    "        # number of test_instance 6\n",
    "        self.test_instance_6 = []\n",
    "\n",
    "    # load the data\n",
    "    def tusimple_load_from_json(self):\n",
    "        # train data load\n",
    "        print(\"* Train Data Load Start\")\n",
    "        for idx, label_file in enumerate(self.train_label_files):\n",
    "            # print(\"* {} : {} Load Start\".format(idx, label_file))\n",
    "\n",
    "            with open(self.train_path + label_file) as f:\n",
    "                for line in f.readlines():\n",
    "                    json_line = json.loads(line)\n",
    "                    self.train_data.append(json_line)\n",
    "\n",
    "            # print(\"* {} : {} Load Finish\".format(idx, label_file))\n",
    "        self.train_size = len(self.train_data)\n",
    "\n",
    "        print(\"* Train Data Load Finish\")\n",
    "\n",
    "        # test data load\n",
    "        print(\"* Test Data Load Start\")\n",
    "\n",
    "        for idx, label_file in enumerate(self.test_label_files):\n",
    "            # print(\"* {} : {} Load Start\".format(idx, label_file))\n",
    "\n",
    "            with open(self.test_path + label_file) as f:\n",
    "                for line in f.readlines():\n",
    "                    json_line = json.loads(line)\n",
    "                    self.test_data.append(json_line)\n",
    "\n",
    "        self.test_size = len(self.test_data)\n",
    "\n",
    "        print(\"* Test Data Load Finish\")\n",
    "\n",
    "    # split according to the number of instances\n",
    "    def tusimple_split_instance(self):\n",
    "        print(\"**-----------------------------------------------**\")\n",
    "        print(\"* Train Data Split Start\")\n",
    "        # train data split\n",
    "        for idx,instance in enumerate(self.train_data):\n",
    "            if len(instance['lanes']) == 1:\n",
    "                self.train_instance_1.append(instance)\n",
    "            elif len(instance['lanes']) == 2:\n",
    "                self.train_instance_2.append(instance)\n",
    "            elif len(instance['lanes']) == 3:\n",
    "                self.train_instance_3.append(instance)\n",
    "            elif len(instance['lanes']) == 4:\n",
    "                self.train_instance_4.append(instance)\n",
    "            elif len(instance['lanes']) == 5:\n",
    "                self.train_instance_5.append(instance)\n",
    "            elif len(instance['lanes']) == 6:\n",
    "                self.train_instance_6.append(instance)\n",
    "\n",
    "\n",
    "        print(\"num_train_instance_1 : {}\".format(len(self.train_instance_1)))\n",
    "        print(\"num_train_instance_2 : {}\".format(len(self.train_instance_2)))\n",
    "        print(\"num_train_instance_3 : {}\".format(len(self.train_instance_3)))\n",
    "        print(\"num_train_instance_4 : {}\".format(len(self.train_instance_4)))\n",
    "        print(\"num_train_instance_5 : {}\".format(len(self.train_instance_5)))\n",
    "        print(\"num_train_instance_6 : {}\".format(len(self.train_instance_6)))\n",
    "\n",
    "\n",
    "        print(\"* Train Data Split Finish\")\n",
    "        print(\"**-----------------------------------------------**\")\n",
    "\n",
    "        print(\"* Test Data Split Start\")\n",
    "\n",
    "        # test data split\n",
    "        for idx,instance in enumerate(self.test_data):\n",
    "            if len(instance['lanes']) == 1:\n",
    "                self.test_instance_1.append(instance)\n",
    "            elif len(instance['lanes']) == 2:\n",
    "                self.test_instance_2.append(instance)\n",
    "            elif len(instance['lanes']) == 3:\n",
    "                self.test_instance_3.append(instance)\n",
    "            elif len(instance['lanes']) == 4:\n",
    "                self.test_instance_4.append(instance)\n",
    "            elif len(instance['lanes']) == 5:\n",
    "                self.test_instance_5.append(instance)\n",
    "            elif len(instance['lanes']) == 6:\n",
    "                self.test_instance_6.append(instance)\n",
    "\n",
    "        print(\"num_test_instance_1 : {}\".format(len(self.test_instance_1)))\n",
    "        print(\"num_test_instance_2 : {}\".format(len(self.test_instance_2)))\n",
    "        print(\"num_test_instance_3 : {}\".format(len(self.test_instance_3)))\n",
    "        print(\"num_test_instance_4 : {}\".format(len(self.test_instance_4)))\n",
    "        print(\"num_test_instance_5 : {}\".format(len(self.test_instance_5)))\n",
    "        print(\"num_test_instance_6 : {}\".format(len(self.test_instance_6)))\n",
    "\n",
    "        print(\"* Test Data Split Finish\")\n",
    "\n",
    "        print(\"**-----------------------------------------------**\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "tusimple_manager = Tusimple_Manager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Train Data Load Start\n",
      "* Train Data Load Finish\n",
      "* Test Data Load Start\n",
      "* Test Data Load Finish\n"
     ]
    }
   ],
   "source": [
    "tusimple_manager.tusimple_load_from_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**-----------------------------------------------**\n",
      "* Train Data Split Start\n",
      "num_train_instance_1 : 0\n",
      "num_train_instance_2 : 1\n",
      "num_train_instance_3 : 404\n",
      "num_train_instance_4 : 2982\n",
      "num_train_instance_5 : 239\n",
      "num_train_instance_6 : 0\n",
      "* Train Data Split Finish\n",
      "**-----------------------------------------------**\n",
      "* Test Data Split Start\n",
      "num_test_instance_1 : 0\n",
      "num_test_instance_2 : 5\n",
      "num_test_instance_3 : 1740\n",
      "num_test_instance_4 : 468\n",
      "num_test_instance_5 : 569\n",
      "num_test_instance_6 : 0\n",
      "* Test Data Split Finish\n",
      "**-----------------------------------------------**\n"
     ]
    }
   ],
   "source": [
    "tusimple_manager.tusimple_split_instance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'lanes': [[-2, -2, -2, -2, -2, -2, -2, 802, 748, 713, 688, 663, 639, 620, 600, 580, 560, 541, 521, 503, 488, 474, 459, 444, 429, 414, 399, 384, 369, 354, 339, 324, 309, 294, 279, 264, 250, 235, 220, 205, 190, 175, 160, 145, 130, 115, 100, 85, 70, 55, 40, 26, 11, -2, -2, -2], [-2, -2, -2, -2, -2, -2, -2, -2, 841, 814, 808, 801, 795, 798, 801, 804, 807, 810, 814, 820, 826, 832, 839, 845, 852, 860, 868, 876, 884, 892, 900, 908, 915, 923, 931, 939, 947, 955, 963, 970, 978, 986, 994, 1002, 1010, 1018, 1026, 1033, 1041, 1049, 1057, 1065, 1073, 1081, 1088, 1096]], 'h_samples': [160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380, 390, 400, 410, 420, 430, 440, 450, 460, 470, 480, 490, 500, 510, 520, 530, 540, 550, 560, 570, 580, 590, 600, 610, 620, 630, 640, 650, 660, 670, 680, 690, 700, 710], 'raw_file': 'clips/0531/1492629882697772610/20.jpg'}]\n"
     ]
    }
   ],
   "source": [
    "print(tusimple_manager.train_instance_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "train_set = None\n",
    "test_set = None\n",
    "\n",
    "for idx, instance in enumerate(tusimple_manager.train_instance_3):\n",
    "    clip_dir = tusimple_manager.train_path + instance['raw_file']\n",
    "    \n",
    "    image = cv2.imread(clip_dir)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    \n",
    "    lane_arr = list(instance['lanes'])\n",
    "    \n",
    "    lane_arr = np.array(lane_arr)\n",
    "    lane_arr = np.flip(lane_arr, axis=2)\n",
    "    \n",
    "    train_set = lane_arr[: , : 45]\n",
    "    test_set = lane_arr[:, 45: ]\n",
    "    \n",
    "    print(train_set)\n",
    "    print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = MinMaxScaler()\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ss = ss.fit_transform(train_set)\n",
    "test_ss = ss.fit_transform(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ss))\n",
    "print(len(test_ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_ss[:1, :]\n",
    "x_test = train_ss[1:, :]\n",
    "\n",
    "y_train = test_ss[:1, :]\n",
    "y_test = test_ss[1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape : (1, 45) (1, 11)\n",
      "Test Shape : (1, 45) (1, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Shape : {} {}\".format(x_train.shape,y_train.shape))\n",
    "print(\"Test Shape : {} {}\".format(x_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensors = Variable(torch.Tensor(x_train))\n",
    "x_test_tensors = Variable(torch.Tensor(x_test))\n",
    "\n",
    "y_train_tensors = Variable(torch.Tensor(y_train))\n",
    "y_test_tensors = Variable(torch.Tensor(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensors_final = torch.reshape(x_train_tensors,   (x_train_tensors.shape[0], 1, x_train_tensors.shape[1]))\n",
    "\n",
    "\n",
    "X_test_tensors_final = torch.reshape(x_test_tensors,  (x_test_tensors.shape[0], 1, x_test_tensors.shape[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM1(nn.Module):\n",
    "  def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "    super(LSTM1, self).__init__()\n",
    "    self.num_classes = num_classes\n",
    "    self.num_layers = num_layers\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.seq_length = seq_length\n",
    "\n",
    "    self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "    self.fc_1 = nn.Linear(hidden_size, 128)\n",
    "    self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    self.relu = nn.ReLU()\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, x):\n",
    "    h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
    "\n",
    "    c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
    "\n",
    "    output, (hn, cn) = self.lstm(x, (h_0, c_0))\n",
    "\n",
    "    hn = hn.view(-1, self.hidden_size)\n",
    "\n",
    "    out = self.sigmoid(hn)\n",
    "\n",
    "    out = self.fc_1(out)\n",
    "\n",
    "    out = self.relu(out)\n",
    "\n",
    "    out = self.fc(out)\n",
    "\n",
    "    return out[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "learning_rate = 0.001\n",
    "\n",
    "input_size = 45\n",
    "hidden_size = 11\n",
    "num_layers = 10\n",
    "\n",
    "num_classes = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm1 = LSTM1(num_classes, input_size, hidden_size, num_layers, X_train_tensors_final.shape[1]) # 1 5 2 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(lstm1.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, loss : 0.35371\n",
      "Epoch : 10, loss : 0.18581\n",
      "Epoch : 20, loss : 0.07294\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "  outputs = lstm1.forward(X_train_tensors_final)\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  loss = criterion(outputs, y_train_tensors[0])\n",
    "\n",
    "  loss.backward()\n",
    "\n",
    "  optimizer.step()\n",
    "\n",
    "  if epoch%10 == 0:\n",
    "    print(\"Epoch : %d, loss : %1.5f\" % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-141-8a032f74c27f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-141-8a032f74c27f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    df_X_ss =\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
